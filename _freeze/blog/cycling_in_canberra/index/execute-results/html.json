{
  "hash": "8c0adf74271d03c3714076b053986ca4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Cycling in Canberra\"\ndescription: \"\"\nauthor: \"Johann Wagner\"\ndate: \"2025-03-18\"\ncategories:\n  - \"Exploratory Data Analysis\"\n  - \"Cycling\"\n---\n\n\n\n## Context\n### Personal Interest\n\n### Data Context\nThis dataset contains the number of trips counted by the bike barometer located on the Sullivan's Creek shared path at the intersection with MacArthur Avenue in O'Connor.\n\nThe data is recorded in hourly intervals, and is collected using an induction loop similar to systems used for traffic light monitoring. Trips in both directions are included in the recorded counts.\n\n## Setup and Configuration\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(httr2)\nlibrary(skimr)\n```\n:::\n\n\n\n## Data Loading (with API)\nWe'll access the Canberra Bike Barometer data via an API.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbase_url <- \"https://www.data.act.gov.au/resource/62sb-92ea.json\"\nreq <- request(base_url)\n\nresp <- req |> \n  req_perform()\n\nres <- resp |> \n  resp_body_json()\n```\n:::\n\n\n\nUnfortunately, the API service has a default limit of providing 1000 rows, so we will have to do some smart looping to ensure we get the complete dataset. We will set our limit parameter to 1000 and create a new function to make a GET API request.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlimit <- 1000\n\nget_data <- function(offset) {\n  url <- paste0(base_url, \"?$offset=\", offset, \"&$limit=\", limit)\n  request(url) |> \n    req_perform() |> \n    resp_body_json()\n}\n```\n:::\n\n\n\nNow, we can create a `while` loop to fetch the data in chunks. We can increment the `offset` parameter in each iteration and store the fetched data in `raw_bike_data`.The `tryCatch` function is used to handle potential errors during the request. So long the http response code is 200, the loop will not break. If the response is empty `length(result) == 0`, it means there's no more data and the loop will break.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbike_data <- list()\noffset <- 0\n\nwhile (TRUE) {\n  print(paste(\"Offset:\", offset))\n  result <- tryCatch({\n    get_data(offset)\n  }, error = function(e) {\n    print(paste(\"Error fetching data:\", e$message))\n    return(NULL)\n  })\n  \n  if (is.null(result) || length(result) == 0) {\n    break\n  }\n  \n  bike_data <- c(bike_data, result)\n  offset <- offset + limit\n  \n  # Mindful of rate limits to avoid being blocked by the API\n  Sys.sleep(1)\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Offset: 0\"\n[1] \"Offset: 1000\"\n[1] \"Offset: 2000\"\n[1] \"Offset: 3000\"\n[1] \"Offset: 4000\"\n[1] \"Offset: 5000\"\n[1] \"Offset: 6000\"\n[1] \"Offset: 7000\"\n[1] \"Offset: 8000\"\n[1] \"Offset: 9000\"\n[1] \"Offset: 10000\"\n[1] \"Offset: 11000\"\n[1] \"Offset: 12000\"\n[1] \"Offset: 13000\"\n[1] \"Offset: 14000\"\n[1] \"Offset: 15000\"\n[1] \"Offset: 16000\"\n[1] \"Offset: 17000\"\n[1] \"Offset: 18000\"\n[1] \"Offset: 19000\"\n[1] \"Offset: 20000\"\n[1] \"Offset: 21000\"\n[1] \"Offset: 22000\"\n[1] \"Offset: 23000\"\n[1] \"Offset: 24000\"\n[1] \"Offset: 25000\"\n[1] \"Offset: 26000\"\n[1] \"Offset: 27000\"\n[1] \"Offset: 28000\"\n[1] \"Offset: 29000\"\n[1] \"Offset: 30000\"\n[1] \"Offset: 31000\"\n[1] \"Offset: 32000\"\n[1] \"Offset: 33000\"\n[1] \"Offset: 34000\"\n[1] \"Offset: 35000\"\n[1] \"Offset: 36000\"\n[1] \"Offset: 37000\"\n[1] \"Offset: 38000\"\n[1] \"Offset: 39000\"\n[1] \"Offset: 40000\"\n[1] \"Offset: 41000\"\n[1] \"Offset: 42000\"\n[1] \"Offset: 43000\"\n[1] \"Offset: 44000\"\n[1] \"Offset: 45000\"\n[1] \"Offset: 46000\"\n[1] \"Offset: 47000\"\n```\n\n\n:::\n\n```{.r .cell-code}\nraw_bike_data <- bike_data |> \n  map_dfr(as_tibble)\n```\n:::\n\n\n\n### Sanity Checks - Raw Data\nHurray! Let's do some sanity checks / data quality checks.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskim(raw_bike_data)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |              |\n|:------------------------|:-------------|\n|Name                     |raw_bike_data |\n|Number of rows           |46200         |\n|Number of columns        |4             |\n|_______________________  |              |\n|Column type frequency:   |              |\n|character                |4             |\n|________________________ |              |\n|Group variables          |None          |\n\n\n**Variable type: character**\n\n|skim_variable                     | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:---------------------------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|date_time                         |         0|             1|  23|  23|     0|    46200|          0|\n|count                             |         0|             1|   1|   3|     0|      463|          0|\n|macarthur_ave_display_cyclist_in  |         0|             1|   1|   3|     0|      407|          0|\n|macarthur_ave_display_cyclist_out |         0|             1|   1|   3|     0|      319|          0|\n\n\n:::\n:::\n\n\n\nGreat! It's very reassuring to see 46200 unique `datetime` values. We'll need to do some data cleaning and adjust `count`, `macarthur_ave_display_cyclist_in`, `macarthur_ave_display_cyclist_out` to be numeric values. Nevertheless, we can see that the min and max values are presumably between 0 and at most 999, which seems reasonable for hourly bike counts. We've also got no missing/empty values.\n\nThe great thing about the above code is that hopefully it remains reproducible once ACT Government releases more recent data! This could be converted into an R package (a later project).\n\n## Data Cleaning\nLet's make those minor variable changes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_bike_data <- raw_bike_data |> \n  mutate(\n    date_time = date_time |> \n      str_sub(1, 13) |> \n      as_datetime(format = \"%Y-%m-%dT%H\"),\n    across(\n      !date_time,\n      as.integer\n    )\n  )\nclean_bike_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 46,200 × 4\n   date_time           count macarthur_ave_display_cycl…¹ macarthur_ave_displa…²\n   <dttm>              <int>                        <int>                  <int>\n 1 2017-11-22 00:00:00    13                            3                     10\n 2 2017-11-22 01:00:00     2                            2                      0\n 3 2017-11-22 02:00:00     0                            0                      0\n 4 2017-11-22 03:00:00     0                            0                      0\n 5 2017-11-22 04:00:00     1                            1                      0\n 6 2017-11-22 05:00:00     9                            5                      4\n 7 2017-11-22 06:00:00    28                           25                      3\n 8 2017-11-22 07:00:00   157                          149                      8\n 9 2017-11-22 08:00:00   358                          315                     43\n10 2017-11-22 09:00:00   144                          131                     13\n# ℹ 46,190 more rows\n# ℹ abbreviated names: ¹​macarthur_ave_display_cyclist_in,\n#   ²​macarthur_ave_display_cyclist_out\n```\n\n\n:::\n:::\n\n\n\n### Sanity Checks - Clean Data\nNow, that the data is cleaned we can do some more sanity checks. The average number of cyclists passing through the Macarthur Avenue crossing is 43.5533766. However, there is quite a right-skewed distribution (mostly low counts by the hour). Interestingly, there's a slightly more cyclists heading into the city than out of the city. Our dataset ranges between 2017-11-22 and 2017-11-22.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskim(clean_bike_data)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |                |\n|:------------------------|:---------------|\n|Name                     |clean_bike_data |\n|Number of rows           |46200           |\n|Number of columns        |4               |\n|_______________________  |                |\n|Column type frequency:   |                |\n|numeric                  |3               |\n|POSIXct                  |1               |\n|________________________ |                |\n|Group variables          |None            |\n\n\n**Variable type: numeric**\n\n|skim_variable                     | n_missing| complete_rate|  mean|    sd| p0| p25| p50| p75| p100|hist  |\n|:---------------------------------|---------:|-------------:|-----:|-----:|--:|---:|---:|---:|----:|:-----|\n|count                             |         0|             1| 43.55| 61.97|  0|   3|  22|  57|  549|▇▁▁▁▁ |\n|macarthur_ave_display_cyclist_in  |         0|             1| 22.36| 44.18|  0|   1|   8|  24|  471|▇▁▁▁▁ |\n|macarthur_ave_display_cyclist_out |         0|             1| 21.19| 36.24|  0|   1|   9|  25|  368|▇▁▁▁▁ |\n\n\n**Variable type: POSIXct**\n\n|skim_variable | n_missing| complete_rate|min        |max                 |median              | n_unique|\n|:-------------|---------:|-------------:|:----------|:-------------------|:-------------------|--------:|\n|date_time     |         0|             1|2017-11-22 |2023-02-28 23:00:00 |2020-07-11 11:30:00 |    46200|\n\n\n:::\n:::\n\n\n\n## Time series\nLet's see how the number of bikes changes across time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_bike_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 46,200 × 4\n   date_time           count macarthur_ave_display_cycl…¹ macarthur_ave_displa…²\n   <dttm>              <int>                        <int>                  <int>\n 1 2017-11-22 00:00:00    13                            3                     10\n 2 2017-11-22 01:00:00     2                            2                      0\n 3 2017-11-22 02:00:00     0                            0                      0\n 4 2017-11-22 03:00:00     0                            0                      0\n 5 2017-11-22 04:00:00     1                            1                      0\n 6 2017-11-22 05:00:00     9                            5                      4\n 7 2017-11-22 06:00:00    28                           25                      3\n 8 2017-11-22 07:00:00   157                          149                      8\n 9 2017-11-22 08:00:00   358                          315                     43\n10 2017-11-22 09:00:00   144                          131                     13\n# ℹ 46,190 more rows\n# ℹ abbreviated names: ¹​macarthur_ave_display_cyclist_in,\n#   ²​macarthur_ave_display_cyclist_out\n```\n\n\n:::\n:::\n\n\n\n## Days of the week\n\n## Time of day\n\n## GitHub calendar\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
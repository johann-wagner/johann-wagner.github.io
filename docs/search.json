[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome!\n\nHi, I‚Äôm Johann! üñê\n\nNice to meet you! üòä\nI‚Äôm an economic/data analyst at the Department of Education (Australian Government). I completed my Bachelor of Economics minoring in Econometrics and Bachelor of Science majoring in Quantitative Environmental Modelling and minoring in Applied Statistics from the Australian National University in 2023. You can access my CV here.\n\nPassion\n\nData Analysis\nData Visualisation\nPublic Health Data\nEnvironmental Data\n\n\n\nExtra-Curricalar\n\nCo-Chair Data Analyst Network 2024\nUltimate Frisbee\nAdventure Racing\nRogaining\nMountain Biking\nRunning\n\n\n\nYou can contact me via:\n\nLinkedIn\nGitHub\nEmail: johann.wagner@gmail.com\n\nThis website was built using Quarto. The source code can be found here. I‚Äôd like to thank Marvin Schmitt and Melissa Van Bussell for their tutorials on how to build a website using Quarto.\nüíÖüíÖüíÖ"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "About this site\nTesting R code block\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Blog Sub-Page\nWork in Progress"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Here are some of my past and current projects:"
  },
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "CV",
    "section": "",
    "text": "Download current CV\n  \n\n\n  \n\nDownload Johann‚Äôs CV."
  },
  {
    "objectID": "projects/index.html#invasive-species-rshiny-dashboard",
    "href": "projects/index.html#invasive-species-rshiny-dashboard",
    "title": "Projects",
    "section": "Invasive Species RShiny Dashboard",
    "text": "Invasive Species RShiny Dashboard\n\nPurpose:\nThis project is complete. The dashboard is currently hosted on shinyapps.io. The dashboard is still in the early stages of development and there are still many improvements to be made. The next step is to incorporate the dashboard into this website and share this work with the Atlas of Living Australia.\n\n\nProject Scope:\nThis project was the final assignment for the Data Science for Biologists (DS4B) university course.\nThe project had the following brief: Your task is to:\n\nchoose a dataset or combination of datasets\ndevelop some questions/aims related to that dataset, including appropriate background research\nuse R t |&gt; o address those questions/aims\nwrite your findings into a report of up to 2000 words and 10 figures\nsummarise your findings in a poster which you will present in the week 12 workshop\n\nIdeally, you should choose a combination of dataset and questions/aims that are interesting to you, because the more interesting you find it, the better your work will be!\n\n\nLinks:\n\nRShiny Dashboard\nPoster\nGitHub Repository"
  },
  {
    "objectID": "projects/index.html#spotify-data-analysis",
    "href": "projects/index.html#spotify-data-analysis",
    "title": "Projects",
    "section": "Spotify Data Analysis",
    "text": "Spotify Data Analysis\n\nPurpose:\nThis project is complete. The dashboard is currently hosted on shinyapps.io. The dashboard is still in the early stages of development and there are still many improvements to be made. The next step is to incorporate the dashboard into this website and share this work with the Atlas of Living Australia.\n\n\nProject Scope:\nThis project was the final assignment for the Data Science for Biologists (DS4B) university course.\nThe project had the following brief: Your task is to:\n\nchoose a dataset or combination of datasets\ndevelop some questions/aims related to that dataset, including appropriate background research\nuse R t |&gt; o address those questions/aims\nwrite your findings into a report of up to 2000 words and 10 figures\nsummarise your findings in a poster which you will present in the week 12 workshop\n\nIdeally, you should choose a combination of dataset and questions/aims that are interesting to you, because the more interesting you find it, the better your work will be!\n\n\nLinks:\n\nRShiny Dashboard\nPoster\nGitHub Repository"
  },
  {
    "objectID": "projects/index.html#leadership-compass",
    "href": "projects/index.html#leadership-compass",
    "title": "Projects",
    "section": "Leadership Compass",
    "text": "Leadership Compass\n\nPurpose:\nCreate an R script that creates a visualisation of the results from the leadership compass survey.\n\n\nProject Status:\nThis project is currently in progress. There are still major improvements to be made to the visualisation and the data workflow. An excel file containing the survey results is currently being used as the data source. The next step is to create a Google Form to collect the survey results and then use the Google Form API to pull the data into the R script. Potentially, this can further be all incoroprated into an RShiny App.\n\n\nLinks:\n\nGitHub Repository"
  },
  {
    "objectID": "projects/index.html#d20-simulation",
    "href": "projects/index.html#d20-simulation",
    "title": "Projects",
    "section": "D20 Simulation",
    "text": "D20 Simulation\n\nPurpose:\nCalculating the probability mass function of a d20 twenty times and adding a rule of rolling another 6 times if a 20 is rolled.\n\n\nProject Status:\n\nCreate an RShiny Dashboard\nRewrite the code to incorporate rbinom(), instead of using runif().\n\n\n\nLinks:\n\nGitHub Repository"
  },
  {
    "objectID": "projects/index.html#spotify-exploratory-data-analysis",
    "href": "projects/index.html#spotify-exploratory-data-analysis",
    "title": "Projects",
    "section": "Spotify Exploratory Data Analysis",
    "text": "Spotify Exploratory Data Analysis\n\nPurpose:\nExplore Johann‚Äôs personal Spotify data and discover patterns in his listening habits.\n\n\nProject Status:\n\nCurrently working on looking at the streaming history data.\nNext step is to look at the playlist data and await the entire streaming history data to be available (late Jan 2024).\nThe final step is to create an RShiny dashboard to visualise the data and create some basic descriptive statistics.\nIdeally, this RShiny will allow individuals to upload their own personal Spotify data and explore their own listening habits.\nAdditionally, I would like to recreate my own version of the Spotify Wrapped.\nNeed to explore the Spotify API and see how I can integrate it into the RShiny dashboard.\nLook into other people‚Äôs Spotify and R projects to see what I can learn from them.\n\n\n\nLinks:\n\nGitHub Repository.\nSpotify API."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Welcome to Johann‚Äôs posts sub-page.\nI write a variety of content from personal data analysis projects to tutorials on how to use various tools and general personal blog posts as well. I hope you find something useful here! :)\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nSpotify Exploratory Data Analysis - Streaming History Data\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nSpotify Exploratory Data Analysis - Streaming History Data\n\n\n\n\n\n\n\nData Projects\n\n\nExploratory Data Analysis\n\n\nSpotify\n\n\n\n\nMy Spotify streaming history throughout July 2022/2023\n\n\n\n\n\n\nDec 29, 2023\n\n\nJohann Wagner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html",
    "href": "posts/spotify_exploratory_data_analysis/index.html",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "",
    "text": "This is a series of exploratory data analysis (EDA) projects on my Spotify data. The data was downloaded from my Spotify account on July 23rd, 2023. The data is downloaded as a zip file containing several json files and saved on my personal google drive. The json files are then converted into tibbles for analysis using the jsonlite package.\nThis quarto document is the first of several EDA projects. This project focuses on my streaming history. I‚Äôm interested in exploring my listening habits across the time period of the data. I‚Äôm also interested in exploring my listening habits across the days of the week.\nThis process is documented in the following sections:\n\nSetup and Configuration: Loading packages and googledrive API access\nData Loading: How to download and load the data?\nData Tidying: Get a tidy dataset\nData Cleaning: Ensure variables are in correct formats\nData Exploration: Answer one question and come up with two extra ones\n\nLet‚Äôs start exploring!"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html#introduction",
    "href": "posts/spotify_exploratory_data_analysis/index.html#introduction",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "",
    "text": "This is a series of exploratory data analysis (EDA) projects on my Spotify data. The data was downloaded from my Spotify account on July 23rd, 2023. The data is downloaded as a zip file containing several json files and saved on my personal google drive. The json files are then converted into tibbles for analysis using the jsonlite package.\nThis quarto document is the first of several EDA projects. This project focuses on my streaming history. I‚Äôm interested in exploring my listening habits across the time period of the data. I‚Äôm also interested in exploring my listening habits across the days of the week.\nThis process is documented in the following sections:\n\nSetup and Configuration: Loading packages and googledrive API access\nData Loading: How to download and load the data?\nData Tidying: Get a tidy dataset\nData Cleaning: Ensure variables are in correct formats\nData Exploration: Answer one question and come up with two extra ones\n\nLet‚Äôs start exploring!"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html#setup-and-configuration",
    "href": "posts/spotify_exploratory_data_analysis/index.html#setup-and-configuration",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Setup and Configuration",
    "text": "Setup and Configuration\nFirst, let‚Äôs load in the packages we‚Äôll need for this project and authorise access to my google drive.\n\n### \"Tidyverse\"-oriented packages:\n\n# The tidyverse is a collection of R packages designed for data science.\n# All packages share a similar design philosophy, grammar, and data structures.\n# Tidyverse includes packages such as:\n# ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, lubridate, and forcats.\n### https://www.tidyverse.org/\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# To easily create data visualisations with simple and consistent syntax and grammar.\n# https://ggplot2.tidyverse.org/index.html\nlibrary(ggplot2)\n\n# To allow interaction between files on Google Drive and R.\n# https://googledrive.tidyverse.org/\nlibrary(googledrive)\n\n\n\n### Other Packages:\n# To easily create summary statistics to understand and explore data.\n# https://docs.ropensci.org/skimr/\nlibrary(skimr)\n\n# A fast JSON parser and generator.\n### https://cran.r-project.org/web/packages/jsonlite/index.html\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n# To easily enable file referencing in project-oriented workflows.\n# https://here.r-lib.org/\nlibrary(here)\n\nhere() starts at C:/Users/Johan/Documents/GitHub/johann-wagner\n\n# To easily format and scale data in visualisations.\n# https://scales.r-lib.org/\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n# Google Drive Authentication --------------------------------------------------\n\n# To establish a connection between a Google Drive account and R.\ndrive_auth()\n\n! Using an auto-discovered, cached token.\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n  See gargle's \"Non-interactive auth\" vignette for more details:\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\n‚Ñπ The googledrive package is using a cached token for\n  'johann.wagner@gmail.com'.\n\n# Example of how to download from Google Drive\n# drive_download(\n#   # Where to download file from\n#   \"https://drive.google.com/file/d/1Fjq1r6016H4isB2Cx2wg-Xm9zY7lHhYV/view?usp=drive_link\",\n# \n#   # Where to save it locally\n#   path = here(\"foldertest\", \"text2\")\n#   )"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html#data-loading",
    "href": "posts/spotify_exploratory_data_analysis/index.html#data-loading",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Loading",
    "text": "Data Loading\nTo access the data, I need to download it from my google drive. The data is requested from Johann‚Äôs Spotify account and downloaded as a zip file containing several json files. There are several different json files; however, for this analysis I‚Äôm only interested in the Streaming History files.\nYou will only have access if Johann has given you read access to the email you authorised in 0-00_setup_and_configuration.R.\n\n# Only download raw data if it hasn't already been downloaded\nif(!dir.exists(here(\"raw_data\"))) {\n  dir.create(here(\"raw_data\"), showWarnings = FALSE)\n\n  # List contents of Spotify Analysis Folder\n  spotify_dribble &lt;- drive_ls(\"Spotify Analysis\")\n  \n  # Download raw data\n  map2(\n    spotify_dribble$id,\n    spotify_dribble$name,\n    ~ drive_download(\n      file = as_id(.x),\n      path = here(\"raw_data\", .y),\n      overwrite = TRUE\n    )\n  )\n}\n\n\n\n# Read in individual raw json as nested lists\n# JRAW = RAW JSON\n# RAW_JSON causes alphabetical ordering inconveniences in R environment.\nJRAW_STREAMING_HISTORY_0 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory0.json\"\n  )\n)\n\nJRAW_STREAMING_HISTORY_1 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory1.json\"\n  )\n)\n\nJRAW_STREAMING_HISTORY_2 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory2.json\"\n  )\n)"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html#data-tidying",
    "href": "posts/spotify_exploratory_data_analysis/index.html#data-tidying",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Tidying",
    "text": "Data Tidying\nThese json files are then converted into tibbles for analysis using the jsonlite package. The tibbles are then combined into one tibble, as they all have the same columns. I suspect the reason why there are different files is because of the size of the data.\n\nRAW_STREAMING_HISTORY_0 &lt;- JRAW_STREAMING_HISTORY_0 %&gt;% \n  bind_rows() %&gt;% \n  as_tibble()\n\nRAW_STREAMING_HISTORY_1 &lt;- JRAW_STREAMING_HISTORY_1 %&gt;% \n  bind_rows() |&gt; \n  as_tibble()\n\nRAW_STREAMING_HISTORY_2 &lt;- JRAW_STREAMING_HISTORY_2 %&gt;% \n  bind_rows() |&gt; \n  as_tibble()\n\n# Combine all streaming history tibbles into one tibble\nRAW_STREAMING_HISTORY &lt;- bind_rows(\n  RAW_STREAMING_HISTORY_0,\n  RAW_STREAMING_HISTORY_1,\n  RAW_STREAMING_HISTORY_2\n)"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html#data-cleaning",
    "href": "posts/spotify_exploratory_data_analysis/index.html#data-cleaning",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nLet‚Äôs ensure the variables are in the correct format.\n\nCLEANED_STREAMING_HISTORY &lt;- RAW_STREAMING_HISTORY |&gt; \n  mutate(\n    # Convert ms to minutes\n    min_played = as.numeric(msPlayed / 60000),\n    \n    # Convert artistName to factor\n    artist_name = as.factor(artistName),\n    \n    track_name = as.character(trackName),\n    \n    # Convert endTime into lubridate datetime\n    streaming_datetime = as_date(endTime, format = \"%Y-%m-%d %H:%M\")\n  ) |&gt; \n  \n  # Remove unnecessary columns\n  select(\n    artist_name,\n    track_name,\n    streaming_datetime,\n    min_played\n  )"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html#data-exploration",
    "href": "posts/spotify_exploratory_data_analysis/index.html#data-exploration",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Exploration",
    "text": "Data Exploration\nThis data exploration has two objectives: 1. To get a sense of the data and to see if there are any issues with the data. 2. To answer several questions that I have about my listening habits.\n\nSanity Checks\nThere are 23456 rows in the CLEANED_STREAMING_HISTORY tibble, which is the number of songs/podcast episodes that I have listened to between 2022-07-11 and 2023-07-11. Let‚Äôs use the function skim() from the skimr package to get a sense check of the data.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  skim()\n\n\nData summary\n\n\nName\nCLEANED_STREAMING_HISTORY\n\n\nNumber of rows\n23456\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nDate\n1\n\n\nfactor\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntrack_name\n0\n1\n1\n179\n0\n7782\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstreaming_datetime\n0\n1\n2022-07-11\n2023-07-11\n2022-12-01\n337\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nartist_name\n0\n1\nFALSE\n4324\nPar: 1147, Van: 271, Cou: 217, Lof: 183\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nmin_played\n0\n1\n3.01\n2.8\n0\n1.56\n3.08\n4\n82.34\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\nThere are 4 columns in the CLEANED_STREAMING_HISTORY tibble. There are 4324 unique artists and 7782 unique tracks in the CLEANED_STREAMING_HISTORY tibble. It is interesting that the shortest track_name has a length of 1 characters and the longest track_name has a length of 179 characters. Interestingly, the shortest track_name has a length of 1 characters. I wonder what song that is. The date ranges between 2022-07-11 and 2023-07-11.\nIt seems like the data mostly makes sense and that there are a wide range of song names and artist names.\n\n\nReshape Data: Streaming per day\nLet‚Äôs reshape the data so that we can see how much I have streamed per day.\n\nSTREAMING_HISTORY_PER_DAY &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  group_by(streaming_datetime) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  )\nSTREAMING_HISTORY_PER_DAY\n\n# A tibble: 337 √ó 2\n   streaming_datetime total_hours_played\n   &lt;date&gt;                          &lt;dbl&gt;\n 1 2022-07-11                      2.41 \n 2 2022-07-12                      5.31 \n 3 2022-07-13                      2.78 \n 4 2022-07-14                      3.52 \n 5 2022-07-15                      4.38 \n 6 2022-07-16                      9.42 \n 7 2022-07-17                      4.99 \n 8 2022-07-18                      3.64 \n 9 2022-07-19                      3.78 \n10 2022-07-20                      0.147\n# ‚Ñπ 327 more rows\n\n\n\n\nWhat were the top 5 days I listened to music?\nLet‚Äôs now investigate what the top 5 days I listened to music were and include the day of the week.\n\nTOP_SONGS &lt;- STREAMING_HISTORY_PER_DAY |&gt;\n  mutate(\n    day_of_week = wday(streaming_datetime, label = TRUE)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(5)\nTOP_SONGS\n\n# A tibble: 5 √ó 3\n  streaming_datetime total_hours_played day_of_week\n  &lt;date&gt;                          &lt;dbl&gt; &lt;ord&gt;      \n1 2023-05-30                       17.2 Tue        \n2 2023-02-18                       13.9 Sat        \n3 2022-11-01                       11.9 Tue        \n4 2022-12-16                       11.8 Fri        \n5 2022-09-02                       11.2 Fri        \n\n\nIt seems like 2023-05-30 and 2023-02-18 were two days when I listened to a LOT of music.\nLet‚Äôs pull it back and look at the aggregate again; I wonder what the most listened to days are?\n\nSTREAMING_HISTORY_PER_DAY |&gt; \n  mutate(\n    day_of_week = wday(streaming_datetime, label = TRUE)\n    ) |&gt; \n  group_by(day_of_week) |&gt;\n  summarise(\n    total_hours_played = sum(total_hours_played)\n  ) |&gt;\n  arrange(desc(total_hours_played))\n\n# A tibble: 7 √ó 2\n  day_of_week total_hours_played\n  &lt;ord&gt;                    &lt;dbl&gt;\n1 Mon                       199.\n2 Tue                       185.\n3 Sat                       180.\n4 Fri                       164.\n5 Thu                       157.\n6 Sun                       151.\n7 Wed                       140.\n\n\nSurprisingly, it seems like Mondays are the days where I have listened to the most streamed music. I wonder if this is because I listen to music on my commute to work? Although, I don‚Äôt think I was really working consistently in 2022-23.\nSo potentially this is because I listen to music when I was studying? To answer this question and gain more insights, I would need to look at my calendar and see what I was doing on those days.\n\n\nHow did my streaming time vary by day?\nLet‚Äôs plot the total hours played per day.\n\nGGPLOT_HOURS_PLAYED_PER_DAY &lt;- STREAMING_HISTORY_PER_DAY |&gt; \n  ggplot(aes(x = streaming_datetime, y = total_hours_played)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Hours Played Per Day\",\n    subtitle = \"Spotify Streaming History\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\nGGPLOT_HOURS_PLAYED_PER_DAY\n\n\n\n\nThere is a high fluctuation in the number of hours played per day with some days, when very little music was played and some days were a lot of music was played. It seems that there are two days in particular, where I have listened to a lot of music. Let‚Äôs investigate these days further, we know that the days are: 2023-05-30 and 2023-02-18. What did I do on these two days? Let‚Äôs also include a smoothed line.\n\nGGPLOT_HOURS_PLAYED_PER_DAY +\n  \n  geom_point(aes(\n    colour = ifelse(\n      streaming_datetime == as.Date(\"2023-05-30\") | \n        streaming_datetime == as.Date(\"2023-02-18\"),\n      \"red\",\n      \"darkgrey\"\n    )\n    )\n  ) +\n  geom_line(colour = \"darkgrey\") +\n  geom_smooth() +\n  geom_label(\n    label = \"Flying to Australia\",\n    x = as.Date(\"2023-05-30\"),\n    y = STREAMING_HISTORY_PER_DAY |&gt; \n      filter(streaming_datetime == as.Date(\"2023-05-30\")) |&gt; \n      pull(total_hours_played),\n    vjust = -0.5\n  ) +\n  geom_label(\n    label = \"Flying to Austria\",\n    x = as.Date(\"2023-02-18\"),\n    y = STREAMING_HISTORY_PER_DAY |&gt; \n      filter(streaming_datetime == as.Date(\"2023-02-18\")) |&gt; \n      pull(total_hours_played),\n    vjust = -0.5\n  ) +\n    expand_limits(\n    y = c(0, 20)\n  ) +\n  scale_color_identity()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nFlying in the plane and listening to music! That makes sense. The smoothed line suggests that there was more music listened to in the second half of 2022 than the first half of 2023.\n\n\nHow did my streaming time vary by month?\nLet‚Äôs investigate this further: what was the total number of hours played per month?\n\nSTREAMING_HISTORY_PER_MONTH &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\"),\n    year_floor = floor_date(streaming_datetime, unit = \"year\")\n  ) |&gt; \n  group_by(month_floor, year_floor) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  )\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\nLet‚Äôs plot the total hours played per month.\n\nSTREAMING_HISTORY_PER_MONTH |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Hours Played Per Month\",\n    subtitle = \"Spotify Streaming History\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\n\n\n\nThere seems to be a bit of a pattern. Before I went backpacking (Jan 2023), I was listening to a lot more music. Let‚Äôs calculate the total number of hours played in both years and see how different they are.\n\nSTREAMING_HISTORY_PER_MONTH |&gt; \n  group_by(year_floor) |&gt;\n  summarise(\n    total_hours_played = sum(total_hours_played)\n  )\n\n# A tibble: 2 √ó 2\n  year_floor total_hours_played\n  &lt;date&gt;                  &lt;dbl&gt;\n1 2022-01-01               697.\n2 2023-01-01               481.\n\n\nThere definitely seems like there is a major difference between the two years. I wonder if this is because I was travelling in 2023 and therefore didn‚Äôt have as much time to listen to music. Let‚Äôs investigate this further.\n\n\nWho were my top artists?\nLet‚Äôs investigate who my top artists are. We will do this by grouping by artist name and then calculating the total number of hours played.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  group_by(artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(10) |&gt; \n  ggplot(aes(x = reorder(artist_name, total_hours_played), y = total_hours_played)) +\n  geom_col(aes(fill = ifelse(total_hours_played &gt; 20, \"orange\", \"grey\"))) +\n  coord_flip() +\n  scale_y_continuous(\n    breaks = seq(0, 100, 10)\n  ) +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Artists\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\"\n  ) +\n  theme_minimal()\n\n\n\n\nAs expected, I‚Äôm a massive Parcels fan and the data shows it! Let‚Äôs look at my top artists for each month.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt; \n  group_by(month_floor, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  group_by(month_floor) |&gt; \n  slice(1) |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played, fill = artist_name)) +\n  geom_col() +\n  scale_fill_viridis_d() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Artists Per Month\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\n\n\n\nWow, Parcels really was my favourite artist consistently throughout the time range, although from April 2023 onwards, it seems I started listening to more podcasts. A further question for future investigation: How does my podcast listening behaviour change over time.\n\n\nWhat were my top songs?\nLet‚Äôs move onto top songs. We will do this by grouping by track name and then calculating the total number of hours played.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  group_by(track_name, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(10) |&gt; \n  ggplot(aes(x = reorder(track_name, total_hours_played), y = total_hours_played)) +\n  geom_col(aes(fill = ifelse(artist_name == \"Parcels\", \"orange\", \"grey\"))) +\n  coord_flip() +\n  scale_y_continuous(\n    breaks = seq(0, 10, 2)\n  ) +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Songs\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\\nOrange = Parcels\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'track_name'. You can override using the\n`.groups` argument.\n\n\n\n\n\nFive of the top 10 songs were songs from Parcels.\nLet‚Äôs look at the top songs for each month.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt; \n  group_by(month_floor, track_name, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  group_by(month_floor) |&gt; \n  slice(1) |&gt; \n  mutate(\n    fill_colour = case_when(\n      track_name == \"Lost in Music - Dimitri from Paris Remix\" ~ \"pink\",\n      artist_name == \"Parcels\" ~ \"orange\",\n      .default = \"grey\"\n      )\n  ) |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played, fill = fill_colour)) +\n  geom_col() +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Songs Per Month\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\\nOrange = Parcels\\nPink = Lost in Music - Dimitri from Paris Remix\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'month_floor', 'track_name'. You can\noverride using the `.groups` argument.\n\n\n\n\n\nIt seems that I listened to Lost in Music - Dimitri from Paris Remix a lot in July/August 2022. Parcels was my top artist for every month, but it seems that I listened to them a lot more in October 2022 and January/Febuary 2023.\n\n\nHow did my top 10 songs vary across time?\nLet‚Äôs investigate how my top 10 songs varied across time. We will do this by grouping by track name and then calculating the total number of hours played.\n\ntop_ten_songs &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  group_by(track_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(5) |&gt; \n  pull(track_name)\n\nCLEANED_STREAMING_HISTORY |&gt;\n  filter(track_name %in% top_ten_songs) |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt;\n  group_by(month_floor, track_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt;\n  ggplot(aes(x = month_floor, y = total_hours_played, colour = track_name)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top 5 Songs - Hours Played Per Day\",\n    subtitle = \"Spotify Streaming History\",\n    colour = \"Track Name\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\n\n\n\nThis is super interesting. It seems that there are some rough patterns in my top 5 songs. For example, ‚ÄúLost in Music - Dimitri from Paris Remix‚Äù was played a lot in the first half of 2022 and then not at all in the first half of 2023. Similarly, ‚ÄúThe Girl‚Äù has a similar downwards trend. ‚ÄúTieduprightnow‚Äù was played a lot in the new year (2023); however, also dropped. ‚ÄúFree‚Äù and ‚ÄúBitter Sweet Symphony‚Äù were almost perfectly positively correlated with each other with the exception of late 2022.\nI wonder if I could do this analysis for all of my songs and then create a grouping/cluster analysis to see if there are any temporal patterns in my music listening? Are there some songs that I listen to with other songs? Do these songs group together because I usually listen to them from the same playlist? Can I somehow link/predict my playlist data and my streaming data?"
  },
  {
    "objectID": "posts/spotify_exploratory_data_analysis/index.html#moving-forward",
    "href": "posts/spotify_exploratory_data_analysis/index.html#moving-forward",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Moving Forward",
    "text": "Moving Forward\nThere are quite a few questions that I would like to explore in the future. For example: - I would like to explore how my podcast listening behaviour change over time. - I would like to explore how my top 10 songs varied across time and utilise the gganimate package. - I would really like to do some time series analysis on my streaming history. - I‚Äôm curious on linking my streaming history data with my playlist data. I wonder if I can predict my playlist data based on my streaming history data. I think I would typically use Spotify by listening to my playlists, so potentially doing some clustering/grouping analysis on my streaming history data and then linking it to my playlist data would be interesting.\nThese are all questions that I would like to explore in future! But for now, these were some great first initial data explorations of my Spotify streaming history. I hope you enjoyed reading this post and I hope you learned something new about Spotify streaming history data analysis. If you have any questions or comments, please feel free to reach out to me. I would love to hear from you! :)"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "",
    "text": "This is a series of exploratory data analysis (EDA) projects on my Spotify data. The data was downloaded from my Spotify account on July 23rd, 2023. The data is downloaded as a zip file containing several json files and saved on my personal google drive. The json files are then converted into tibbles for analysis using the jsonlite package.\nThis quarto document is the first of several EDA projects. This project focuses on my streaming history. I‚Äôm interested in exploring my listening habits across the time period of the data. I‚Äôm also interested in exploring my listening habits across the days of the week.\nThis process is documented in the following sections:\n\nSetup and Configuration: Loading packages and googledrive API access\nData Loading: How to download and load the data?\nData Tidying: Get a tidy dataset\nData Cleaning: Ensure variables are in correct formats\nData Exploration: Answer one question and come up with two extra ones\n\nLet‚Äôs start exploring!"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html#introduction",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html#introduction",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "",
    "text": "This is a series of exploratory data analysis (EDA) projects on my Spotify data. The data was downloaded from my Spotify account on July 23rd, 2023. The data is downloaded as a zip file containing several json files and saved on my personal google drive. The json files are then converted into tibbles for analysis using the jsonlite package.\nThis quarto document is the first of several EDA projects. This project focuses on my streaming history. I‚Äôm interested in exploring my listening habits across the time period of the data. I‚Äôm also interested in exploring my listening habits across the days of the week.\nThis process is documented in the following sections:\n\nSetup and Configuration: Loading packages and googledrive API access\nData Loading: How to download and load the data?\nData Tidying: Get a tidy dataset\nData Cleaning: Ensure variables are in correct formats\nData Exploration: Answer one question and come up with two extra ones\n\nLet‚Äôs start exploring!"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html#setup-and-configuration",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html#setup-and-configuration",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Setup and Configuration",
    "text": "Setup and Configuration\nFirst, let‚Äôs load in the packages we‚Äôll need for this project and authorise access to my google drive.\n\n### \"Tidyverse\"-oriented packages:\n\n# The tidyverse is a collection of R packages designed for data science.\n# All packages share a similar design philosophy, grammar, and data structures.\n# Tidyverse includes packages such as:\n# ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, lubridate, and forcats.\n### https://www.tidyverse.org/\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# To easily create data visualisations with simple and consistent syntax and grammar.\n# https://ggplot2.tidyverse.org/index.html\nlibrary(ggplot2)\n\n# To allow interaction between files on Google Drive and R.\n# https://googledrive.tidyverse.org/\nlibrary(googledrive)\n\n\n\n### Other Packages:\n# To easily create summary statistics to understand and explore data.\n# https://docs.ropensci.org/skimr/\nlibrary(skimr)\n\n# A fast JSON parser and generator.\n### https://cran.r-project.org/web/packages/jsonlite/index.html\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n# To easily enable file referencing in project-oriented workflows.\n# https://here.r-lib.org/\nlibrary(here)\n\nhere() starts at C:/Users/Johan/Documents/GitHub/johann-wagner\n\n# To easily format and scale data in visualisations.\n# https://scales.r-lib.org/\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n# Google Drive Authentication --------------------------------------------------\n\n# To establish a connection between a Google Drive account and R.\ndrive_auth()\n\n! Using an auto-discovered, cached token.\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n  See gargle's \"Non-interactive auth\" vignette for more details:\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\n‚Ñπ The googledrive package is using a cached token for\n  'johann.wagner@gmail.com'.\n\n# Example of how to download from Google Drive\n# drive_download(\n#   # Where to download file from\n#   \"https://drive.google.com/file/d/1Fjq1r6016H4isB2Cx2wg-Xm9zY7lHhYV/view?usp=drive_link\",\n# \n#   # Where to save it locally\n#   path = here(\"foldertest\", \"text2\")\n#   )"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html#data-loading",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html#data-loading",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Loading",
    "text": "Data Loading\nTo access the data, I need to download it from my google drive. The data is requested from Johann‚Äôs Spotify account and downloaded as a zip file containing several json files. There are several different json files; however, for this analysis I‚Äôm only interested in the Streaming History files.\nYou will only have access if Johann has given you read access to the email you authorised in 0-00_setup_and_configuration.R.\n\n# Only download raw data if it hasn't already been downloaded\nif(!dir.exists(here(\"raw_data\"))) {\n  dir.create(here(\"raw_data\"), showWarnings = FALSE)\n\n  # List contents of Spotify Analysis Folder\n  spotify_dribble &lt;- drive_ls(\"Spotify Analysis\")\n  \n  # Download raw data\n  map2(\n    spotify_dribble$id,\n    spotify_dribble$name,\n    ~ drive_download(\n      file = as_id(.x),\n      path = here(\"raw_data\", .y),\n      overwrite = TRUE\n    )\n  )\n}\n\n\n\n# Read in individual raw json as nested lists\n# JRAW = RAW JSON\n# RAW_JSON causes alphabetical ordering inconveniences in R environment.\nJRAW_STREAMING_HISTORY_0 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory0.json\"\n  )\n)\n\nJRAW_STREAMING_HISTORY_1 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory1.json\"\n  )\n)\n\nJRAW_STREAMING_HISTORY_2 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory2.json\"\n  )\n)"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html#data-tidying",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html#data-tidying",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Tidying",
    "text": "Data Tidying\nThese json files are then converted into tibbles for analysis using the jsonlite package. The tibbles are then combined into one tibble, as they all have the same columns. I suspect the reason why there are different files is because of the size of the data.\n\nRAW_STREAMING_HISTORY_0 &lt;- JRAW_STREAMING_HISTORY_0 %&gt;% \n  bind_rows() %&gt;% \n  as_tibble()\n\nRAW_STREAMING_HISTORY_1 &lt;- JRAW_STREAMING_HISTORY_1 %&gt;% \n  bind_rows() |&gt; \n  as_tibble()\n\nRAW_STREAMING_HISTORY_2 &lt;- JRAW_STREAMING_HISTORY_2 %&gt;% \n  bind_rows() |&gt; \n  as_tibble()\n\n# Combine all streaming history tibbles into one tibble\nRAW_STREAMING_HISTORY &lt;- bind_rows(\n  RAW_STREAMING_HISTORY_0,\n  RAW_STREAMING_HISTORY_1,\n  RAW_STREAMING_HISTORY_2\n)"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html#data-cleaning",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html#data-cleaning",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nLet‚Äôs ensure the variables are in the correct format.\n\nCLEANED_STREAMING_HISTORY &lt;- RAW_STREAMING_HISTORY |&gt; \n  mutate(\n    # Convert ms to minutes\n    min_played = as.numeric(msPlayed / 60000),\n    \n    # Convert artistName to factor\n    artist_name = as.factor(artistName),\n    \n    track_name = as.character(trackName),\n    \n    # Convert endTime into lubridate datetime\n    streaming_datetime = as_date(endTime, format = \"%Y-%m-%d %H:%M\")\n  ) |&gt; \n  \n  # Remove unnecessary columns\n  select(\n    artist_name,\n    track_name,\n    streaming_datetime,\n    min_played\n  )"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html#data-exploration",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html#data-exploration",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Exploration",
    "text": "Data Exploration\nThis data exploration has two objectives: 1. To get a sense of the data and to see if there are any issues with the data. 2. To answer several questions that I have about my listening habits.\n\nSanity Checks\nThere are 23456 rows in the CLEANED_STREAMING_HISTORY tibble, which is the number of songs/podcast episodes that I have listened to between 2022-07-11 and 2023-07-11. Let‚Äôs use the function skim() from the skimr package to get a sense check of the data.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  skim()\n\n\nData summary\n\n\nName\nCLEANED_STREAMING_HISTORY\n\n\nNumber of rows\n23456\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nDate\n1\n\n\nfactor\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntrack_name\n0\n1\n1\n179\n0\n7782\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstreaming_datetime\n0\n1\n2022-07-11\n2023-07-11\n2022-12-01\n337\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nartist_name\n0\n1\nFALSE\n4324\nPar: 1147, Van: 271, Cou: 217, Lof: 183\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nmin_played\n0\n1\n3.01\n2.8\n0\n1.56\n3.08\n4\n82.34\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\nThere are 4 columns in the CLEANED_STREAMING_HISTORY tibble. There are 4324 unique artists and 7782 unique tracks in the CLEANED_STREAMING_HISTORY tibble. It is interesting that the shortest track_name has a length of 1 characters and the longest track_name has a length of 179 characters. Interestingly, the shortest track_name has a length of 1 characters. I wonder what song that is. The date ranges between 2022-07-11 and 2023-07-11.\nIt seems like the data mostly makes sense and that there are a wide range of song names and artist names.\n\n\nReshape Data: Streaming per day\nLet‚Äôs reshape the data so that we can see how much I have streamed per day.\n\nSTREAMING_HISTORY_PER_DAY &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  group_by(streaming_datetime) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  )\nSTREAMING_HISTORY_PER_DAY\n\n# A tibble: 337 √ó 2\n   streaming_datetime total_hours_played\n   &lt;date&gt;                          &lt;dbl&gt;\n 1 2022-07-11                      2.41 \n 2 2022-07-12                      5.31 \n 3 2022-07-13                      2.78 \n 4 2022-07-14                      3.52 \n 5 2022-07-15                      4.38 \n 6 2022-07-16                      9.42 \n 7 2022-07-17                      4.99 \n 8 2022-07-18                      3.64 \n 9 2022-07-19                      3.78 \n10 2022-07-20                      0.147\n# ‚Ñπ 327 more rows\n\n\n\n\nWhat were the top 5 days I listened to music?\nLet‚Äôs now investigate what the top 5 days I listened to music were and include the day of the week.\n\nTOP_SONGS &lt;- STREAMING_HISTORY_PER_DAY |&gt;\n  mutate(\n    day_of_week = wday(streaming_datetime, label = TRUE)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(5)\nTOP_SONGS\n\n# A tibble: 5 √ó 3\n  streaming_datetime total_hours_played day_of_week\n  &lt;date&gt;                          &lt;dbl&gt; &lt;ord&gt;      \n1 2023-05-30                       17.2 Tue        \n2 2023-02-18                       13.9 Sat        \n3 2022-11-01                       11.9 Tue        \n4 2022-12-16                       11.8 Fri        \n5 2022-09-02                       11.2 Fri        \n\n\nIt seems like 2023-05-30 and 2023-02-18 were two days when I listened to a LOT of music.\nLet‚Äôs pull it back and look at the aggregate again; I wonder what the most listened to days are?\n\nSTREAMING_HISTORY_PER_DAY |&gt; \n  mutate(\n    day_of_week = wday(streaming_datetime, label = TRUE)\n    ) |&gt; \n  group_by(day_of_week) |&gt;\n  summarise(\n    total_hours_played = sum(total_hours_played)\n  ) |&gt;\n  arrange(desc(total_hours_played))\n\n# A tibble: 7 √ó 2\n  day_of_week total_hours_played\n  &lt;ord&gt;                    &lt;dbl&gt;\n1 Mon                       199.\n2 Tue                       185.\n3 Sat                       180.\n4 Fri                       164.\n5 Thu                       157.\n6 Sun                       151.\n7 Wed                       140.\n\n\nSurprisingly, it seems like Mondays are the days where I have listened to the most streamed music. I wonder if this is because I listen to music on my commute to work? Although, I don‚Äôt think I was really working consistently in 2022-23.\nSo potentially this is because I listen to music when I was studying? To answer this question and gain more insights, I would need to look at my calendar and see what I was doing on those days.\n\n\nHow did my streaming time vary by day?\nLet‚Äôs plot the total hours played per day.\n\nGGPLOT_HOURS_PLAYED_PER_DAY &lt;- STREAMING_HISTORY_PER_DAY |&gt; \n  ggplot(aes(x = streaming_datetime, y = total_hours_played)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Hours Played Per Day\",\n    subtitle = \"Spotify Streaming History\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\nGGPLOT_HOURS_PLAYED_PER_DAY\n\n\n\n\nThere is a high fluctuation in the number of hours played per day with some days, when very little music was played and some days were a lot of music was played. It seems that there are two days in particular, where I have listened to a lot of music. Let‚Äôs investigate these days further, we know that the days are: 2023-05-30 and 2023-02-18. What did I do on these two days? Let‚Äôs also include a smoothed line.\n\nGGPLOT_HOURS_PLAYED_PER_DAY +\n  \n  geom_point(aes(\n    colour = ifelse(\n      streaming_datetime == as.Date(\"2023-05-30\") | \n        streaming_datetime == as.Date(\"2023-02-18\"),\n      \"red\",\n      \"darkgrey\"\n    )\n    )\n  ) +\n  geom_line(colour = \"darkgrey\") +\n  geom_smooth() +\n  geom_label(\n    label = \"Flying to Australia\",\n    x = as.Date(\"2023-05-30\"),\n    y = STREAMING_HISTORY_PER_DAY |&gt; \n      filter(streaming_datetime == as.Date(\"2023-05-30\")) |&gt; \n      pull(total_hours_played),\n    vjust = -0.5\n  ) +\n  geom_label(\n    label = \"Flying to Austria\",\n    x = as.Date(\"2023-02-18\"),\n    y = STREAMING_HISTORY_PER_DAY |&gt; \n      filter(streaming_datetime == as.Date(\"2023-02-18\")) |&gt; \n      pull(total_hours_played),\n    vjust = -0.5\n  ) +\n    expand_limits(\n    y = c(0, 20)\n  ) +\n  scale_color_identity()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nFlying in the plane and listening to music! That makes sense. The smoothed line suggests that there was more music listened to in the second half of 2022 than the first half of 2023.\n\n\nHow did my streaming time vary by month?\nLet‚Äôs investigate this further: what was the total number of hours played per month?\n\nSTREAMING_HISTORY_PER_MONTH &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\"),\n    year_floor = floor_date(streaming_datetime, unit = \"year\")\n  ) |&gt; \n  group_by(month_floor, year_floor) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  )\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\nLet‚Äôs plot the total hours played per month.\n\nSTREAMING_HISTORY_PER_MONTH |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Hours Played Per Month\",\n    subtitle = \"Spotify Streaming History\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\n\n\n\nThere seems to be a bit of a pattern. Before I went backpacking (Jan 2023), I was listening to a lot more music. Let‚Äôs calculate the total number of hours played in both years and see how different they are.\n\nSTREAMING_HISTORY_PER_MONTH |&gt; \n  group_by(year_floor) |&gt;\n  summarise(\n    total_hours_played = sum(total_hours_played)\n  )\n\n# A tibble: 2 √ó 2\n  year_floor total_hours_played\n  &lt;date&gt;                  &lt;dbl&gt;\n1 2022-01-01               697.\n2 2023-01-01               481.\n\n\nThere definitely seems like there is a major difference between the two years. I wonder if this is because I was travelling in 2023 and therefore didn‚Äôt have as much time to listen to music. Let‚Äôs investigate this further.\n\n\nWho were my top artists?\nLet‚Äôs investigate who my top artists are. We will do this by grouping by artist name and then calculating the total number of hours played.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  group_by(artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(10) |&gt; \n  ggplot(aes(x = reorder(artist_name, total_hours_played), y = total_hours_played)) +\n  geom_col(aes(fill = ifelse(total_hours_played &gt; 20, \"orange\", \"grey\"))) +\n  coord_flip() +\n  scale_y_continuous(\n    breaks = seq(0, 100, 10)\n  ) +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Artists\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\"\n  ) +\n  theme_minimal()\n\n\n\n\nAs expected, I‚Äôm a massive Parcels fan and the data shows it! Let‚Äôs look at my top artists for each month.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt; \n  group_by(month_floor, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  group_by(month_floor) |&gt; \n  slice(1) |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played, fill = artist_name)) +\n  geom_col() +\n  scale_fill_viridis_d() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Artists Per Month\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\n\n\n\nWow, Parcels really was my favourite artist consistently throughout the time range, although from April 2023 onwards, it seems I started listening to more podcasts. A further question for future investigation: How does my podcast listening behaviour change over time.\n\n\nWhat were my top songs?\nLet‚Äôs move onto top songs. We will do this by grouping by track name and then calculating the total number of hours played.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  group_by(track_name, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(10) |&gt; \n  ggplot(aes(x = reorder(track_name, total_hours_played), y = total_hours_played)) +\n  geom_col(aes(fill = ifelse(artist_name == \"Parcels\", \"orange\", \"grey\"))) +\n  coord_flip() +\n  scale_y_continuous(\n    breaks = seq(0, 10, 2)\n  ) +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Songs\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\\nOrange = Parcels\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'track_name'. You can override using the\n`.groups` argument.\n\n\n\n\n\nFive of the top 10 songs were songs from Parcels.\nLet‚Äôs look at the top songs for each month.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt; \n  group_by(month_floor, track_name, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  group_by(month_floor) |&gt; \n  slice(1) |&gt; \n  mutate(\n    fill_colour = case_when(\n      track_name == \"Lost in Music - Dimitri from Paris Remix\" ~ \"pink\",\n      artist_name == \"Parcels\" ~ \"orange\",\n      .default = \"grey\"\n      )\n  ) |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played, fill = fill_colour)) +\n  geom_col() +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Songs Per Month\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\\nOrange = Parcels\\nPink = Lost in Music - Dimitri from Paris Remix\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'month_floor', 'track_name'. You can\noverride using the `.groups` argument.\n\n\n\n\n\nIt seems that I listened to Lost in Music - Dimitri from Paris Remix a lot in July/August 2022. Parcels was my top artist for every month, but it seems that I listened to them a lot more in October 2022 and January/Febuary 2023.\n\n\nHow did my top 10 songs vary across time?\nLet‚Äôs investigate how my top 10 songs varied across time. We will do this by grouping by track name and then calculating the total number of hours played.\n\ntop_ten_songs &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  group_by(track_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(5) |&gt; \n  pull(track_name)\n\nCLEANED_STREAMING_HISTORY |&gt;\n  filter(track_name %in% top_ten_songs) |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt;\n  group_by(month_floor, track_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt;\n  ggplot(aes(x = month_floor, y = total_hours_played, colour = track_name)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top 5 Songs - Hours Played Per Day\",\n    subtitle = \"Spotify Streaming History\",\n    colour = \"Track Name\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\n\n\n\nThis is super interesting. It seems that there are some rough patterns in my top 5 songs. For example, ‚ÄúLost in Music - Dimitri from Paris Remix‚Äù was played a lot in the first half of 2022 and then not at all in the first half of 2023. Similarly, ‚ÄúThe Girl‚Äù has a similar downwards trend. ‚ÄúTieduprightnow‚Äù was played a lot in the new year (2023); however, also dropped. ‚ÄúFree‚Äù and ‚ÄúBitter Sweet Symphony‚Äù were almost perfectly positively correlated with each other with the exception of late 2022.\nI wonder if I could do this analysis for all of my songs and then create a grouping/cluster analysis to see if there are any temporal patterns in my music listening? Are there some songs that I listen to with other songs? Do these songs group together because I usually listen to them from the same playlist? Can I somehow link/predict my playlist data and my streaming data?"
  },
  {
    "objectID": "posts/posts/spotify_exploratory_data_analysis/index.html#moving-forward",
    "href": "posts/posts/spotify_exploratory_data_analysis/index.html#moving-forward",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Moving Forward",
    "text": "Moving Forward\nThere are quite a few questions that I would like to explore in the future. For example: - I would like to explore how my podcast listening behaviour change over time. - I would like to explore how my top 10 songs varied across time and utilise the gganimate package. - I would really like to do some time series analysis on my streaming history. - I‚Äôm curious on linking my streaming history data with my playlist data. I wonder if I can predict my playlist data based on my streaming history data. I think I would typically use Spotify by listening to my playlists, so potentially doing some clustering/grouping analysis on my streaming history data and then linking it to my playlist data would be interesting.\nThese are all questions that I would like to explore in future! But for now, these were some great first initial data explorations of my Spotify streaming history. I hope you enjoyed reading this post and I hope you learned something new about Spotify streaming history data analysis. If you have any questions or comments, please feel free to reach out to me. I would love to hear from you! :)"
  },
  {
    "objectID": "posts_sub_page/index.html",
    "href": "posts_sub_page/index.html",
    "title": "Posts",
    "section": "",
    "text": "Welcome to Johann‚Äôs posts sub-page.\nI write a variety of content from personal data analysis projects to tutorials on how to use various tools and general personal blog posts as well. I hope you find something useful here! :)\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nSpotify Exploratory Data Analysis - Streaming History Data\n\n\n\n\n\n\n\nData Projects\n\n\nExploratory Data Analysis\n\n\nSpotify\n\n\n\n\nMy Spotify streaming history throughout July 2022/2023\n\n\n\n\n\n\nDec 29, 2023\n\n\nJohann Wagner\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "",
    "text": "This is a series of exploratory data analysis (EDA) projects on my Spotify data. The data was downloaded from my Spotify account on July 23rd, 2023. The data is downloaded as a zip file containing several json files and saved on my personal google drive. The json files are then converted into tibbles for analysis using the jsonlite package.\nThis quarto document is the first of several EDA projects. This project focuses on my streaming history. I‚Äôm interested in exploring my listening habits across the time period of the data. I‚Äôm also interested in exploring my listening habits across the days of the week.\nThis process is documented in the following sections:\n\nSetup and Configuration: Loading packages and googledrive API access\nData Loading: How to download and load the data?\nData Tidying: Get a tidy dataset\nData Cleaning: Ensure variables are in correct formats\nData Exploration: Answer one question and come up with two extra ones\n\nLet‚Äôs start exploring!"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#introduction",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#introduction",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "",
    "text": "This is a series of exploratory data analysis (EDA) projects on my Spotify data. The data was downloaded from my Spotify account on July 23rd, 2023. The data is downloaded as a zip file containing several json files and saved on my personal google drive. The json files are then converted into tibbles for analysis using the jsonlite package.\nThis quarto document is the first of several EDA projects. This project focuses on my streaming history. I‚Äôm interested in exploring my listening habits across the time period of the data. I‚Äôm also interested in exploring my listening habits across the days of the week.\nThis process is documented in the following sections:\n\nSetup and Configuration: Loading packages and googledrive API access\nData Loading: How to download and load the data?\nData Tidying: Get a tidy dataset\nData Cleaning: Ensure variables are in correct formats\nData Exploration: Answer one question and come up with two extra ones\n\nLet‚Äôs start exploring!"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#setup-and-configuration",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#setup-and-configuration",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Setup and Configuration",
    "text": "Setup and Configuration\nFirst, let‚Äôs load in the packages we‚Äôll need for this project and authorise access to my google drive.\n\n### \"Tidyverse\"-oriented packages:\n\n# The tidyverse is a collection of R packages designed for data science.\n# All packages share a similar design philosophy, grammar, and data structures.\n# Tidyverse includes packages such as:\n# ggplot2, dplyr, tidyr, readr, purr, tibble, stringr, lubridate, and forcats.\n### https://www.tidyverse.org/\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.4\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.4.4     ‚úî tibble    3.2.1\n‚úî lubridate 1.9.3     ‚úî tidyr     1.3.0\n‚úî purrr     1.0.2     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# To easily create data visualisations with simple and consistent syntax and grammar.\n# https://ggplot2.tidyverse.org/index.html\nlibrary(ggplot2)\n\n# To allow interaction between files on Google Drive and R.\n# https://googledrive.tidyverse.org/\nlibrary(googledrive)\n\n\n\n### Other Packages:\n# To easily create summary statistics to understand and explore data.\n# https://docs.ropensci.org/skimr/\nlibrary(skimr)\n\n# A fast JSON parser and generator.\n### https://cran.r-project.org/web/packages/jsonlite/index.html\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n# To easily enable file referencing in project-oriented workflows.\n# https://here.r-lib.org/\nlibrary(here)\n\nhere() starts at C:/Users/Johan/Documents/GitHub/johann-wagner\n\n# To easily format and scale data in visualisations.\n# https://scales.r-lib.org/\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n# Google Drive Authentication --------------------------------------------------\n\n# To establish a connection between a Google Drive account and R.\ndrive_auth()\n\n! Using an auto-discovered, cached token.\n  To suppress this message, modify your code or options to clearly consent to\n  the use of a cached token.\n  See gargle's \"Non-interactive auth\" vignette for more details:\n  &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt;\n‚Ñπ The googledrive package is using a cached token for\n  'johann.wagner@gmail.com'.\n\n# Example of how to download from Google Drive\n# drive_download(\n#   # Where to download file from\n#   \"https://drive.google.com/file/d/1Fjq1r6016H4isB2Cx2wg-Xm9zY7lHhYV/view?usp=drive_link\",\n# \n#   # Where to save it locally\n#   path = here(\"foldertest\", \"text2\")\n#   )"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-loading",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-loading",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Loading",
    "text": "Data Loading\nTo access the data, I need to download it from my google drive. The data is requested from Johann‚Äôs Spotify account and downloaded as a zip file containing several json files. There are several different json files; however, for this analysis I‚Äôm only interested in the Streaming History files.\nYou will only have access if Johann has given you read access to the email you authorised in 0-00_setup_and_configuration.R.\n\n# Only download raw data if it hasn't already been downloaded\nif(!dir.exists(here(\"raw_data\"))) {\n  dir.create(here(\"raw_data\"), showWarnings = FALSE)\n\n  # List contents of Spotify Analysis Folder\n  spotify_dribble &lt;- drive_ls(\"Spotify Analysis\")\n  \n  # Download raw data\n  map2(\n    spotify_dribble$id,\n    spotify_dribble$name,\n    ~ drive_download(\n      file = as_id(.x),\n      path = here(\"raw_data\", .y),\n      overwrite = TRUE\n    )\n  )\n}\n\n\n\n# Read in individual raw json as nested lists\n# JRAW = RAW JSON\n# RAW_JSON causes alphabetical ordering inconveniences in R environment.\nJRAW_STREAMING_HISTORY_0 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory0.json\"\n  )\n)\n\nJRAW_STREAMING_HISTORY_1 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory1.json\"\n  )\n)\n\nJRAW_STREAMING_HISTORY_2 &lt;- read_json(\n  path = here(\n    \"raw_data\",\n    \"StreamingHistory2.json\"\n  )\n)"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-tidying",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-tidying",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Tidying",
    "text": "Data Tidying\nThese json files are then converted into tibbles for analysis using the jsonlite package. The tibbles are then combined into one tibble, as they all have the same columns. I suspect the reason why there are different files is because of the size of the data.\n\nRAW_STREAMING_HISTORY_0 &lt;- JRAW_STREAMING_HISTORY_0 %&gt;% \n  bind_rows() %&gt;% \n  as_tibble()\n\nRAW_STREAMING_HISTORY_1 &lt;- JRAW_STREAMING_HISTORY_1 %&gt;% \n  bind_rows() |&gt; \n  as_tibble()\n\nRAW_STREAMING_HISTORY_2 &lt;- JRAW_STREAMING_HISTORY_2 %&gt;% \n  bind_rows() |&gt; \n  as_tibble()\n\n# Combine all streaming history tibbles into one tibble\nRAW_STREAMING_HISTORY &lt;- bind_rows(\n  RAW_STREAMING_HISTORY_0,\n  RAW_STREAMING_HISTORY_1,\n  RAW_STREAMING_HISTORY_2\n)"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-cleaning",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-cleaning",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nLet‚Äôs ensure the variables are in the correct format.\n\nCLEANED_STREAMING_HISTORY &lt;- RAW_STREAMING_HISTORY |&gt; \n  mutate(\n    # Convert ms to minutes\n    min_played = as.numeric(msPlayed / 60000),\n    \n    # Convert artistName to factor\n    artist_name = as.factor(artistName),\n    \n    track_name = as.character(trackName),\n    \n    # Convert endTime into lubridate datetime\n    streaming_datetime = as_date(endTime, format = \"%Y-%m-%d %H:%M\")\n  ) |&gt; \n  \n  # Remove unnecessary columns\n  select(\n    artist_name,\n    track_name,\n    streaming_datetime,\n    min_played\n  )"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-exploration",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#data-exploration",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Data Exploration",
    "text": "Data Exploration\nThis data exploration has two objectives: 1. To get a sense of the data and to see if there are any issues with the data. 2. To answer several questions that I have about my listening habits.\n\nSanity Checks\nThere are 23456 rows in the CLEANED_STREAMING_HISTORY tibble, which is the number of songs/podcast episodes that I have listened to between 2022-07-11 and 2023-07-11. Let‚Äôs use the function skim() from the skimr package to get a sense check of the data.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  skim()\n\n\nData summary\n\n\nName\nCLEANED_STREAMING_HISTORY\n\n\nNumber of rows\n23456\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nDate\n1\n\n\nfactor\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ntrack_name\n0\n1\n1\n179\n0\n7782\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nstreaming_datetime\n0\n1\n2022-07-11\n2023-07-11\n2022-12-01\n337\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nartist_name\n0\n1\nFALSE\n4324\nPar: 1147, Van: 271, Cou: 217, Lof: 183\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nmin_played\n0\n1\n3.01\n2.8\n0\n1.56\n3.08\n4\n82.34\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\n\n\n\nThere are 4 columns in the CLEANED_STREAMING_HISTORY tibble. There are 4324 unique artists and 7782 unique tracks in the CLEANED_STREAMING_HISTORY tibble. It is interesting that the shortest track_name has a length of 1 characters and the longest track_name has a length of 179 characters. Interestingly, the shortest track_name has a length of 1 characters. I wonder what song that is. The date ranges between 2022-07-11 and 2023-07-11.\nIt seems like the data mostly makes sense and that there are a wide range of song names and artist names.\n\n\nReshape Data: Streaming per day\nLet‚Äôs reshape the data so that we can see how much I have streamed per day.\n\nSTREAMING_HISTORY_PER_DAY &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  group_by(streaming_datetime) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  )\nSTREAMING_HISTORY_PER_DAY\n\n# A tibble: 337 √ó 2\n   streaming_datetime total_hours_played\n   &lt;date&gt;                          &lt;dbl&gt;\n 1 2022-07-11                      2.41 \n 2 2022-07-12                      5.31 \n 3 2022-07-13                      2.78 \n 4 2022-07-14                      3.52 \n 5 2022-07-15                      4.38 \n 6 2022-07-16                      9.42 \n 7 2022-07-17                      4.99 \n 8 2022-07-18                      3.64 \n 9 2022-07-19                      3.78 \n10 2022-07-20                      0.147\n# ‚Ñπ 327 more rows\n\n\n\n\nWhat were the top 5 days I listened to music?\nLet‚Äôs now investigate what the top 5 days I listened to music were and include the day of the week.\n\nTOP_SONGS &lt;- STREAMING_HISTORY_PER_DAY |&gt;\n  mutate(\n    day_of_week = wday(streaming_datetime, label = TRUE)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(5)\nTOP_SONGS\n\n# A tibble: 5 √ó 3\n  streaming_datetime total_hours_played day_of_week\n  &lt;date&gt;                          &lt;dbl&gt; &lt;ord&gt;      \n1 2023-05-30                       17.2 Tue        \n2 2023-02-18                       13.9 Sat        \n3 2022-11-01                       11.9 Tue        \n4 2022-12-16                       11.8 Fri        \n5 2022-09-02                       11.2 Fri        \n\n\nIt seems like 2023-05-30 and 2023-02-18 were two days when I listened to a LOT of music.\nLet‚Äôs pull it back and look at the aggregate again; I wonder what the most listened to days are?\n\nSTREAMING_HISTORY_PER_DAY |&gt; \n  mutate(\n    day_of_week = wday(streaming_datetime, label = TRUE)\n    ) |&gt; \n  group_by(day_of_week) |&gt;\n  summarise(\n    total_hours_played = sum(total_hours_played)\n  ) |&gt;\n  arrange(desc(total_hours_played))\n\n# A tibble: 7 √ó 2\n  day_of_week total_hours_played\n  &lt;ord&gt;                    &lt;dbl&gt;\n1 Mon                       199.\n2 Tue                       185.\n3 Sat                       180.\n4 Fri                       164.\n5 Thu                       157.\n6 Sun                       151.\n7 Wed                       140.\n\n\nSurprisingly, it seems like Mondays are the days where I have listened to the most streamed music. I wonder if this is because I listen to music on my commute to work? Although, I don‚Äôt think I was really working consistently in 2022-23.\nSo potentially this is because I listen to music when I was studying? To answer this question and gain more insights, I would need to look at my calendar and see what I was doing on those days.\n\n\nHow did my streaming time vary by day?\nLet‚Äôs plot the total hours played per day.\n\nGGPLOT_HOURS_PLAYED_PER_DAY &lt;- STREAMING_HISTORY_PER_DAY |&gt; \n  ggplot(aes(x = streaming_datetime, y = total_hours_played)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Hours Played Per Day\",\n    subtitle = \"Spotify Streaming History\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\nGGPLOT_HOURS_PLAYED_PER_DAY\n\n\n\n\nThere is a high fluctuation in the number of hours played per day with some days, when very little music was played and some days were a lot of music was played. It seems that there are two days in particular, where I have listened to a lot of music. Let‚Äôs investigate these days further, we know that the days are: 2023-05-30 and 2023-02-18. What did I do on these two days? Let‚Äôs also include a smoothed line.\n\nGGPLOT_HOURS_PLAYED_PER_DAY +\n  \n  geom_point(aes(\n    colour = ifelse(\n      streaming_datetime == as.Date(\"2023-05-30\") | \n        streaming_datetime == as.Date(\"2023-02-18\"),\n      \"red\",\n      \"darkgrey\"\n    )\n    )\n  ) +\n  geom_line(colour = \"darkgrey\") +\n  geom_smooth() +\n  geom_label(\n    label = \"Flying to Australia\",\n    x = as.Date(\"2023-05-30\"),\n    y = STREAMING_HISTORY_PER_DAY |&gt; \n      filter(streaming_datetime == as.Date(\"2023-05-30\")) |&gt; \n      pull(total_hours_played),\n    vjust = -0.5\n  ) +\n  geom_label(\n    label = \"Flying to Austria\",\n    x = as.Date(\"2023-02-18\"),\n    y = STREAMING_HISTORY_PER_DAY |&gt; \n      filter(streaming_datetime == as.Date(\"2023-02-18\")) |&gt; \n      pull(total_hours_played),\n    vjust = -0.5\n  ) +\n    expand_limits(\n    y = c(0, 20)\n  ) +\n  scale_color_identity()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nFlying in the plane and listening to music! That makes sense. The smoothed line suggests that there was more music listened to in the second half of 2022 than the first half of 2023.\n\n\nHow did my streaming time vary by month?\nLet‚Äôs investigate this further: what was the total number of hours played per month?\n\nSTREAMING_HISTORY_PER_MONTH &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\"),\n    year_floor = floor_date(streaming_datetime, unit = \"year\")\n  ) |&gt; \n  group_by(month_floor, year_floor) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  )\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\nLet‚Äôs plot the total hours played per month.\n\nSTREAMING_HISTORY_PER_MONTH |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Hours Played Per Month\",\n    subtitle = \"Spotify Streaming History\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\n\n\n\nThere seems to be a bit of a pattern. Before I went backpacking (Jan 2023), I was listening to a lot more music. Let‚Äôs calculate the total number of hours played in both years and see how different they are.\n\nSTREAMING_HISTORY_PER_MONTH |&gt; \n  group_by(year_floor) |&gt;\n  summarise(\n    total_hours_played = sum(total_hours_played)\n  )\n\n# A tibble: 2 √ó 2\n  year_floor total_hours_played\n  &lt;date&gt;                  &lt;dbl&gt;\n1 2022-01-01               697.\n2 2023-01-01               481.\n\n\nThere definitely seems like there is a major difference between the two years. I wonder if this is because I was travelling in 2023 and therefore didn‚Äôt have as much time to listen to music. Let‚Äôs investigate this further.\n\n\nWho were my top artists?\nLet‚Äôs investigate who my top artists are. We will do this by grouping by artist name and then calculating the total number of hours played.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  group_by(artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(10) |&gt; \n  ggplot(aes(x = reorder(artist_name, total_hours_played), y = total_hours_played)) +\n  geom_col(aes(fill = ifelse(total_hours_played &gt; 20, \"orange\", \"grey\"))) +\n  coord_flip() +\n  scale_y_continuous(\n    breaks = seq(0, 100, 10)\n  ) +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Artists\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\"\n  ) +\n  theme_minimal()\n\n\n\n\nAs expected, I‚Äôm a massive Parcels fan and the data shows it! Let‚Äôs look at my top artists for each month.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt; \n  group_by(month_floor, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  group_by(month_floor) |&gt; \n  slice(1) |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played, fill = artist_name)) +\n  geom_col() +\n  scale_fill_viridis_d() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Artists Per Month\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\n\n\n\nWow, Parcels really was my favourite artist consistently throughout the time range, although from April 2023 onwards, it seems I started listening to more podcasts. A further question for future investigation: How does my podcast listening behaviour change over time.\n\n\nWhat were my top songs?\nLet‚Äôs move onto top songs. We will do this by grouping by track name and then calculating the total number of hours played.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  group_by(track_name, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(10) |&gt; \n  ggplot(aes(x = reorder(track_name, total_hours_played), y = total_hours_played)) +\n  geom_col(aes(fill = ifelse(artist_name == \"Parcels\", \"orange\", \"grey\"))) +\n  coord_flip() +\n  scale_y_continuous(\n    breaks = seq(0, 10, 2)\n  ) +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Songs\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\\nOrange = Parcels\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'track_name'. You can override using the\n`.groups` argument.\n\n\n\n\n\nFive of the top 10 songs were songs from Parcels.\nLet‚Äôs look at the top songs for each month.\n\nCLEANED_STREAMING_HISTORY |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt; \n  group_by(month_floor, track_name, artist_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  group_by(month_floor) |&gt; \n  slice(1) |&gt; \n  mutate(\n    fill_colour = case_when(\n      track_name == \"Lost in Music - Dimitri from Paris Remix\" ~ \"pink\",\n      artist_name == \"Parcels\" ~ \"orange\",\n      .default = \"grey\"\n      )\n  ) |&gt; \n  ggplot(aes(x = month_floor, y = total_hours_played, fill = fill_colour)) +\n  geom_col() +\n  scale_fill_identity() +\n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top Songs Per Month\",\n    subtitle = \"Spotify Streaming History: July 2022 - July 2023\\nOrange = Parcels\\nPink = Lost in Music - Dimitri from Paris Remix\"\n  ) +\n  theme_minimal()\n\n`summarise()` has grouped output by 'month_floor', 'track_name'. You can\noverride using the `.groups` argument.\n\n\n\n\n\nIt seems that I listened to Lost in Music - Dimitri from Paris Remix a lot in July/August 2022. Parcels was my top artist for every month, but it seems that I listened to them a lot more in October 2022 and January/Febuary 2023.\n\n\nHow did my top 10 songs vary across time?\nLet‚Äôs investigate how my top 10 songs varied across time. We will do this by grouping by track name and then calculating the total number of hours played.\n\ntop_ten_songs &lt;- CLEANED_STREAMING_HISTORY |&gt; \n  group_by(track_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt; \n  arrange(desc(total_hours_played)) |&gt; \n  head(5) |&gt; \n  pull(track_name)\n\nCLEANED_STREAMING_HISTORY |&gt;\n  filter(track_name %in% top_ten_songs) |&gt; \n  mutate(\n    month_floor = floor_date(streaming_datetime, unit = \"month\")\n  ) |&gt;\n  group_by(month_floor, track_name) |&gt;\n  summarise(\n    total_hours_played = sum(min_played / 60)\n  ) |&gt;\n  ggplot(aes(x = month_floor, y = total_hours_played, colour = track_name)) +\n  \n  geom_point() +\n  geom_line() +\n  \n  labs(\n    x = \"\",\n    y = \"Hours Played\",\n    title = \"Top 5 Songs - Hours Played Per Day\",\n    subtitle = \"Spotify Streaming History\",\n    colour = \"Track Name\"\n  ) +\n  \n  theme_minimal() +\n  theme(\n    plot.title = element_text(\n      size = 20,\n      face = \"bold\"\n    ),\n    plot.subtitle = element_text(\n      size = 15\n    ),\n    axis.title = element_text(\n      size = 15\n    ),\n    axis.text = element_text(\n      size = 10\n    )\n  )\n\n`summarise()` has grouped output by 'month_floor'. You can override using the\n`.groups` argument.\n\n\n\n\n\nThis is super interesting. It seems that there are some rough patterns in my top 5 songs. For example, ‚ÄúLost in Music - Dimitri from Paris Remix‚Äù was played a lot in the first half of 2022 and then not at all in the first half of 2023. Similarly, ‚ÄúThe Girl‚Äù has a similar downwards trend. ‚ÄúTieduprightnow‚Äù was played a lot in the new year (2023); however, also dropped. ‚ÄúFree‚Äù and ‚ÄúBitter Sweet Symphony‚Äù were almost perfectly positively correlated with each other with the exception of late 2022.\nI wonder if I could do this analysis for all of my songs and then create a grouping/cluster analysis to see if there are any temporal patterns in my music listening? Are there some songs that I listen to with other songs? Do these songs group together because I usually listen to them from the same playlist? Can I somehow link/predict my playlist data and my streaming data?"
  },
  {
    "objectID": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#moving-forward",
    "href": "posts_sub_page/posts/spotify_exploratory_data_analysis/index.html#moving-forward",
    "title": "Spotify Exploratory Data Analysis - Streaming History Data",
    "section": "Moving Forward",
    "text": "Moving Forward\nThere are quite a few questions that I would like to explore in the future. For example: - I would like to explore how my podcast listening behaviour change over time. - I would like to explore how my top 10 songs varied across time and utilise the gganimate package. - I would really like to do some time series analysis on my streaming history. - I‚Äôm curious on linking my streaming history data with my playlist data. I wonder if I can predict my playlist data based on my streaming history data. I think I would typically use Spotify by listening to my playlists, so potentially doing some clustering/grouping analysis on my streaming history data and then linking it to my playlist data would be interesting.\nThese are all questions that I would like to explore in future! But for now, these were some great first initial data explorations of my Spotify streaming history. I hope you enjoyed reading this post and I hope you learned something new about Spotify streaming history data analysis. If you have any questions or comments, please feel free to reach out to me. I would love to hear from you! :)"
  }
]